{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3521165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1600\n",
      "Test set: 400\n",
      "Dev set: 0\n",
      "Vocabulary size: 13989\n"
     ]
    }
   ],
   "source": [
    "# creating train, dev, and test sets \n",
    "import sentiment_reader\n",
    "import numpy as np\n",
    "\n",
    "# creating sets\n",
    "sentiment_corpus = sentiment_reader.SentimentCorpus()\n",
    "print('Training set:', len(sentiment_corpus.train_X))\n",
    "print('Test set:', len(sentiment_corpus.test_X))\n",
    "print('Dev set:', len(sentiment_corpus.dev_X))\n",
    "print('Vocabulary size:', len(sentiment_corpus.feat_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5cf3906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100, 100),\n",
       "              max_iter=1000, solver='sgd')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training networks using Sigmoid activation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_sig1 = MLPClassifier(hidden_layer_sizes=(100), \n",
    "                         activation='logistic', \n",
    "                         solver='sgd', \n",
    "                         max_iter=1000)\n",
    "mlp_sig1.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())\n",
    "\n",
    "mlp_sig2 = MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                         activation='logistic', \n",
    "                         solver='sgd', \n",
    "                         max_iter=1000)\n",
    "mlp_sig2.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())\n",
    "\n",
    "mlp_sig3 = MLPClassifier(hidden_layer_sizes=(100, 100, 100), \n",
    "                         activation='logistic', \n",
    "                         solver='sgd', \n",
    "                         max_iter=1000)\n",
    "mlp_sig3.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abcd395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 100, 100),\n",
       "              max_iter=1000, solver='sgd')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training networks using Tanh activation\n",
    "mlp_tanh1 = MLPClassifier(hidden_layer_sizes=(100), \n",
    "                          activation='tanh', \n",
    "                          solver='sgd', \n",
    "                          max_iter=1000)\n",
    "mlp_tanh1.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())\n",
    "\n",
    "mlp_tanh2 = MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                          activation='tanh', \n",
    "                          solver='sgd', \n",
    "                          max_iter=1000)\n",
    "mlp_tanh2.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())\n",
    "\n",
    "mlp_tanh3 = MLPClassifier(hidden_layer_sizes=(100, 100, 100), \n",
    "                          activation='tanh', \n",
    "                          solver='sgd', \n",
    "                          max_iter=1000)\n",
    "mlp_tanh3.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74eba39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=1000, solver='sgd')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training networks using RelU activation\n",
    "mlp_relu1 = MLPClassifier(hidden_layer_sizes=(100), \n",
    "                          activation='relu', \n",
    "                          solver='sgd', \n",
    "                          max_iter=1000)\n",
    "mlp_relu1.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())\n",
    "\n",
    "mlp_relu2 = MLPClassifier(hidden_layer_sizes=(100, 100), \n",
    "                          activation='relu', \n",
    "                          solver='sgd', \n",
    "                          max_iter=1000)\n",
    "mlp_relu2.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())\n",
    "\n",
    "mlp_relu3 = MLPClassifier(hidden_layer_sizes=(100, 100, 100), \n",
    "                          activation='relu', \n",
    "                          solver='sgd', \n",
    "                          max_iter=1000)\n",
    "mlp_relu3.fit(sentiment_corpus.train_X, sentiment_corpus.train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cd6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing NNs with test set\n",
    "# calculating metrics for Sigmoid activation\n",
    "prediction_sig1 = mlp_sig1.predict(sentiment_corpus.test_X)\n",
    "accuracy_sig1 = mlp_sig1.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "prediction_sig2 = mlp_sig2.predict(sentiment_corpus.test_X)\n",
    "accuracy_sig2 = mlp_sig2.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "prediction_sig3 = mlp_sig3.predict(sentiment_corpus.test_X)\n",
    "accuracy_sig3 = mlp_sig3.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "\n",
    "# calculating metrics for Tanh activation\n",
    "prediction_tanh1 = mlp_tanh1.predict(sentiment_corpus.test_X)\n",
    "accuracy_tanh1 = mlp_tanh1.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "prediction_tanh2 = mlp_tanh2.predict(sentiment_corpus.test_X)\n",
    "accuracy_tanh2 = mlp_tanh2.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "prediction_tanh3 = mlp_tanh3.predict(sentiment_corpus.test_X)\n",
    "accuracy_tanh3 = mlp_tanh3.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "\n",
    "#calculating metrics for Relu activation\n",
    "prediction_relu1 = mlp_relu1.predict(sentiment_corpus.test_X)\n",
    "accuracy_relu1 = mlp_relu1.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "prediction_relu2 = mlp_relu2.predict(sentiment_corpus.test_X)\n",
    "accuracy_relu2 = mlp_relu2.score(sentiment_corpus.test_X, sentiment_corpus.test_y)\n",
    "prediction_relu3 = mlp_relu3.predict(sentiment_corpus.test_X)\n",
    "accuracy_relu3 = mlp_relu3.score(sentiment_corpus.test_X, sentiment_corpus.test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93532cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 layer model with Signmoid activation function: \n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       212\n",
      "           1       0.81      0.84      0.82       188\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n",
      "2 layer model with Signmoid activation function: \n",
      "Accuracy: 0.4675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       212\n",
      "           1       0.47      0.99      0.64       188\n",
      "\n",
      "    accuracy                           0.47       400\n",
      "   macro avg       0.23      0.50      0.32       400\n",
      "weighted avg       0.22      0.47      0.30       400\n",
      "\n",
      "3 layer model with Signmoid activation function: \n",
      "Accuracy: 0.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       212\n",
      "           1       0.47      1.00      0.64       188\n",
      "\n",
      "    accuracy                           0.47       400\n",
      "   macro avg       0.23      0.50      0.32       400\n",
      "weighted avg       0.22      0.47      0.30       400\n",
      "\n",
      "1 layer model with Tanh activation function: \n",
      "Accuracy: 0.845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       212\n",
      "           1       0.82      0.86      0.84       188\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.85      0.84       400\n",
      "weighted avg       0.85      0.84      0.85       400\n",
      "\n",
      "2 layer model with Tanh activation function: \n",
      "Accuracy: 0.8325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       212\n",
      "           1       0.81      0.84      0.82       188\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n",
      "3 layer model with Tanh activation function: \n",
      "Accuracy: 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       212\n",
      "           1       0.81      0.85      0.83       188\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.84      0.83       400\n",
      "weighted avg       0.84      0.83      0.84       400\n",
      "\n",
      "1 layer model with RelU activation function: \n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       212\n",
      "           1       0.81      0.86      0.83       188\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n",
      "2 layer model with RelU activation function: \n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       212\n",
      "           1       0.82      0.85      0.83       188\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n",
      "3 layer model with RelU activation function: \n",
      "Accuracy: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83       212\n",
      "           1       0.80      0.84      0.82       188\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.83      0.82       400\n",
      "weighted avg       0.83      0.82      0.83       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Michael\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Michael\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# displaying metrics for each trained network\n",
    "from sklearn.metrics import classification_report\n",
    "# metrics for Sigmoid activation\n",
    "print('1 layer model with Signmoid activation function: ')\n",
    "print('Accuracy:', accuracy_sig1)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_sig1))\n",
    "print('2 layer model with Signmoid activation function: ')\n",
    "print('Accuracy:', accuracy_sig2)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_sig2))\n",
    "print('3 layer model with Signmoid activation function: ')\n",
    "print('Accuracy:', accuracy_sig3)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_sig3))\n",
    "\n",
    "# metrics for Tanh activation\n",
    "print('1 layer model with Tanh activation function: ')\n",
    "print('Accuracy:', accuracy_tanh1)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_tanh1))\n",
    "print('2 layer model with Tanh activation function: ')\n",
    "print('Accuracy:', accuracy_tanh2)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_tanh2))\n",
    "print('3 layer model with Tanh activation function: ')\n",
    "print('Accuracy:', accuracy_tanh3)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_tanh3))\n",
    "\n",
    "# metrics for Relu activation\n",
    "print('1 layer model with RelU activation function: ')\n",
    "print('Accuracy:', accuracy_relu1)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_relu1))\n",
    "print('2 layer model with RelU activation function: ')\n",
    "print('Accuracy:', accuracy_relu2)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_relu2))\n",
    "print('3 layer model with RelU activation function: ')\n",
    "print('Accuracy:', accuracy_relu3)\n",
    "print(classification_report(sentiment_corpus.test_y, prediction_relu3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deeb81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "embeddings = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2570f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dictionary, taking the average of bigram embeddings\n",
    "feat_embeddings = sentiment_corpus.feat_counts\n",
    "# iterating over vocabulary in corpus\n",
    "for key in sentiment_corpus.feat_dict.keys():\n",
    "    # temporary embedding to average bigrams\n",
    "    embedding = np.zeros(300, dtype='float32')\n",
    "    # bigrams averaging\n",
    "    if key.find('_') != -1:\n",
    "        normalize = 0\n",
    "        bigrams = key.split('_')\n",
    "        try:\n",
    "            embedding += embeddings[bigrams[0]]\n",
    "            normalize += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "        try:\n",
    "            embedding += embeddings[bigrams[1]]\n",
    "            normalize += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if normalize > 1:\n",
    "            for i in embedding:\n",
    "                normalize = np.array(2.0)\n",
    "                embedding /= normalize\n",
    "                \n",
    "    # adding unigram embeddings\n",
    "    else:\n",
    "        try:\n",
    "            embedding += embeddings[key]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    feat_embeddings[key] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8cab2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "# mapping feature to index\n",
    "embeddings_dict = {}\n",
    "i = 0\n",
    "for key in feat_embeddings.keys():\n",
    "    embeddings_dict[key] = i\n",
    "    i += 1\n",
    "\n",
    "# getting number of positive reviews and breaking input file into a list of reviews\n",
    "reviews = []\n",
    "nr_pos = 0\n",
    "with codecs.open(\"positive.review\", 'r', 'utf8') as pos_file:\n",
    "    for line in pos_file:\n",
    "        nr_pos += 1\n",
    "        sentance = []\n",
    "        toks = line.split(\" \")\n",
    "        for feat in toks[0:-1]:\n",
    "            name, counts = feat.split(\":\")\n",
    "            if name in feat_embeddings:\n",
    "                sentance.append(name)\n",
    "        reviews.append(sentance)\n",
    "                \n",
    "# getting number of positive reviews and breaking input file into a list of reviews        \n",
    "nr_neg = 0\n",
    "with codecs.open(\"negative.review\", 'r', 'utf8') as neg_file:\n",
    "    for line in neg_file:\n",
    "        nr_neg += 1\n",
    "        sentance = []\n",
    "        toks = line.split(\" \")\n",
    "        for feat in toks[0:-1]:\n",
    "            name, counts = feat.split(\":\")\n",
    "            if name in feat_embeddings:\n",
    "                sentance.append(name)\n",
    "        reviews.append(sentance)\n",
    "\n",
    "# creating  a single embedding for each review\n",
    "review_embeddings = []\n",
    "for review in reviews:\n",
    "    words = 0\n",
    "    sentance_embedding = []\n",
    "    for word in review:\n",
    "        if word in embeddings_dict:\n",
    "            if words == 0:\n",
    "                sentance_embedding = feat_embeddings[word]\n",
    "            else:\n",
    "                sentance_embedding = np.add(sentance_embedding, feat_embeddings[word])\n",
    "            words += 1\n",
    "    review_embeddings.append(np.asarray(sentance_embedding)/words)\n",
    "\n",
    "X_embeddings = np.zeros((sentiment_corpus.nr_instances, 300), dtype=object)\n",
    "y_embeddings = np.vstack((np.zeros([nr_pos,1], dtype=int), np.ones([nr_neg,1], dtype=int)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd15804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"positive.review\", 'r', 'utf8') as pos_file:\n",
    "    nr_pos = 0\n",
    "    for line in pos_file:\n",
    "        review = review_embeddings[nr_pos]\n",
    "        for x in range(300):\n",
    "            X_embeddings[nr_pos, x] = review[x]\n",
    "        nr_pos += 1\n",
    "        \n",
    "with codecs.open(\"negative.review\", 'r', 'utf8') as neg_file:\n",
    "    nr_neg = 0\n",
    "    for line in neg_file:\n",
    "        review = review_embeddings[nr_pos+nr_neg]\n",
    "        for x in range(300):\n",
    "            X_embeddings[nr_pos+nr_neg, x] = review[x]\n",
    "        nr_neg += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d271b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the order, mix positive and negative examples\n",
    "new_order = np.arange(sentiment_corpus.nr_instances)\n",
    "np.random.seed(0) # set seed\n",
    "np.random.shuffle(new_order)\n",
    "X_embeddings = X_embeddings[new_order,:]\n",
    "y_embeddings = y_embeddings[new_order,:]\n",
    "    \n",
    "# creating train, test, and dev sets \n",
    "train_y, dev_y, test_y, train_X, dev_X, test_X = sentiment_reader.split_train_dev_test(X_embeddings, y_embeddings, 0.8, 0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1880ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 layer model with Tanh activation function: \n",
      "Accuracy: 0.595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.37      0.49       212\n",
      "           1       0.54      0.85      0.66       188\n",
      "\n",
      "    accuracy                           0.59       400\n",
      "   macro avg       0.64      0.61      0.58       400\n",
      "weighted avg       0.65      0.59      0.57       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_embeddings = MLPClassifier(hidden_layer_sizes=(100), \n",
    "                          activation='tanh', \n",
    "                          solver='sgd', \n",
    "                          max_iter=1000)\n",
    "mlp_embeddings.fit(train_X, train_y.ravel())\n",
    "prediction_embeddings = mlp_embeddings.predict(test_X)\n",
    "accuracy_embeddings = mlp_embeddings.score(test_X, test_y)\n",
    "print('1 layer model with Tanh activation function: ')\n",
    "print('Accuracy:', accuracy_embeddings)\n",
    "print(classification_report(test_y, prediction_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bedd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
